# U-Net Denoising AutoEncoder for EEG Signal Processing

åŸºäº **U-Net** çš„ STFT åŸŸé™å™ªè‡ªç¼–ç å™¨ï¼Œé€‚ç”¨äº EEG / RF / Audio ç­‰ä¸€ç»´ä¿¡å·é™å™ªä»»åŠ¡ã€‚

## ğŸ“‚ é¡¹ç›®ç»“æ„

```
Unet_denosing/
â”œâ”€â”€ data_preparation.py      # æ•°æ®åŠ è½½ã€åˆ‡åˆ†ã€æ··åˆä¸ STFT é¢„å¤„ç†
â”œâ”€â”€ unet_model.py             # U-Net æ¨¡å‹å®šä¹‰ä¸æŸå¤±å‡½æ•°
â”œâ”€â”€ train_unet.py             # è®­ç»ƒè„šæœ¬ï¼ˆæ”¯æŒæ–­ç‚¹ç»­è®­ã€æ—©åœï¼‰
â”œâ”€â”€ inference_unet.py         # æ¨ç†ä¸å¯è§†åŒ–è„šæœ¬
â”œâ”€â”€ data_augmentation.py      # æ•°æ®å¢å¼ºç­–ç•¥
â”œâ”€â”€ README.md                 # æœ¬æ–‡ä»¶
â”œâ”€â”€ checkpoints_unet/         # æ¨¡å‹æ£€æŸ¥ç‚¹ï¼ˆè®­ç»ƒåç”Ÿæˆï¼‰
â”œâ”€â”€ logs_unet/                # TensorBoard æ—¥å¿—ï¼ˆè®­ç»ƒåç”Ÿæˆï¼‰
â”œâ”€â”€ dataset_mixed/            # æ··åˆåçš„æ•°æ®é›†ï¼ˆè¿è¡Œåç”Ÿæˆï¼‰
â””â”€â”€ results_unet/             # æ¨ç†ç»“æœï¼ˆæ¨ç†åç”Ÿæˆï¼‰
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1ï¸âƒ£ ç¯å¢ƒå®‰è£…

```bash
pip install torch torchvision torchaudio
pip install numpy pandas matplotlib scipy scikit-learn tqdm tensorboard
```

### 2ï¸âƒ£ æ•°æ®å‡†å¤‡ä¸è®­ç»ƒ

```bash
# æ–¹å¼ 1: ä½¿ç”¨é»˜è®¤å‚æ•°è®­ç»ƒï¼ˆæ¨èæ–°æ‰‹ï¼‰
python train_unet.py

# æ–¹å¼ 2: è‡ªå®šä¹‰å‚æ•°
python train_unet.py \
    --data_dir 2_Data_processed \
    --num_files 10 \
    --segment_length 2048 \
    --overlap_ratio 0.5 \
    --n_fft 256 \
    --hop_length 64 \
    --mode magnitude \
    --batch_size 16 \
    --epochs 100 \
    --lr 1e-3 \
    --base_channels 64 \
    --depth 4
```

**è®­ç»ƒå‚æ•°è¯´æ˜ï¼š**

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `--data_dir` | `2_Data_processed` | æ•°æ®ç›®å½• |
| `--num_files` | `10` | æ•°æ®æ–‡ä»¶æ•°é‡ï¼ˆ10 ç»„ï¼‰ |
| `--segment_length` | `2048` | ä¿¡å·ç‰‡æ®µé•¿åº¦ |
| `--overlap_ratio` | `0.5` | ç‰‡æ®µé‡å æ¯”ä¾‹ |
| `--test_ratio` | `0.2` | æµ‹è¯•é›†æ¯”ä¾‹ |
| `--n_fft` | `256` | FFT ç‚¹æ•° |
| `--hop_length` | `64` | å¸§ç§» |
| `--mode` | `magnitude` | STFT æ¨¡å¼ï¼ˆ`magnitude` æˆ– `complex`ï¼‰ |
| `--batch_size` | `16` | Batch size |
| `--epochs` | `100` | è®­ç»ƒ epoch æ•° |
| `--lr` | `1e-3` | å­¦ä¹ ç‡ |
| `--base_channels` | `64` | U-Net åŸºç¡€é€šé“æ•° |
| `--depth` | `4` | U-Net æ·±åº¦ |

### 3ï¸âƒ£ æ¨ç†ä¸å¯è§†åŒ–

```bash
# ä½¿ç”¨æœ€ä½³æ¨¡å‹è¿›è¡Œæ¨ç†
python inference_unet.py \
    --model_path checkpoints_unet/best.pth \
    --visualize \
    --save_results \
    --num_visualize 10
```

**æ¨ç†å‚æ•°è¯´æ˜ï¼š**

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `--model_path` | `checkpoints_unet/best.pth` | æ¨¡å‹æƒé‡è·¯å¾„ |
| `--visualize` | `False` | æ˜¯å¦å¯è§†åŒ– |
| `--save_results` | `False` | æ˜¯å¦ä¿å­˜é™å™ªç»“æœ |
| `--num_samples` | `0` | æ¨ç†æ ·æœ¬æ•°ï¼ˆ0 è¡¨ç¤ºå…¨éƒ¨ï¼‰ |
| `--num_visualize` | `5` | å¯è§†åŒ–æ ·æœ¬æ•° |
| `--sample_rate` | `250` | é‡‡æ ·ç‡ï¼ˆç”¨äºå¯è§†åŒ–ï¼‰ |

---

## ğŸ“Š æ¨¡å‹æ¶æ„

### U-Net ç»“æ„

```
è¾“å…¥: (batch, channels, freq, time)
  â””â”€ channels=1 (magnitude æ¨¡å¼) æˆ– 2 (complex æ¨¡å¼)
  â””â”€ freq = n_fft // 2 + 1 (ä¾‹å¦‚ 256//2+1=129)
  â””â”€ time = (segment_length - n_fft) // hop_length + 1

ç¼–ç å™¨ (Encoder):
  DoubleConv(1/2 â†’ 64)
  Down(64 â†’ 128)
  Down(128 â†’ 256)
  Down(256 â†’ 512)
  Down(512 â†’ 1024)

è§£ç å™¨ (Decoder) + è·³è¿:
  Up(1024 â†’ 512) â† skip from Down(256â†’512)
  Up(512 â†’ 256)  â† skip from Down(128â†’256)
  Up(256 â†’ 128)  â† skip from Down(64â†’128)
  Up(128 â†’ 64)   â† skip from DoubleConv

è¾“å‡º: Conv(64 â†’ 1/2)
```

### æŸå¤±å‡½æ•°

- **L1 Loss**: å¹…åº¦è°±å·®å¼‚
- **L2 Loss (MSE)**: èƒ½é‡è¯¯å·®
- **å¤šå°ºåº¦ STFT Loss**ï¼ˆå¯é€‰ï¼‰: å¤šåˆ†è¾¨ç‡é¢‘è°±æŸå¤±

ç»„åˆæŸå¤±ï¼š`Total Loss = Î»1 * L1 + Î»2 * L2`

---

## ğŸ”§ æ ¸å¿ƒåŠŸèƒ½

### 1. æ•°æ®å¤„ç†æµç¨‹

```python
from data_preparation import EEGDataPreparation, create_dataloaders

# åˆå§‹åŒ–
prep = EEGDataPreparation(
    data_dir="2_Data_processed",
    num_files=10,
    test_ratio=0.2,
    random_seed=42
)

# åŠ è½½å…¨éƒ¨æ•°æ®
clean_signals, noisy_signals = prep.load_all_data()

# åˆ‡åˆ†ä¸æ··åˆ
clean_segments, noisy_segments = prep.segment_signals(
    clean_signals, noisy_signals,
    segment_length=2048,
    overlap_ratio=0.5
)

# åˆ’åˆ†è®­ç»ƒ/æµ‹è¯•é›†
clean_train, clean_test, noisy_train, noisy_test = prep.split_train_test(
    clean_segments, noisy_segments
)

# ä¿å­˜æ•°æ®é›†
prep.save_dataset(clean_train, clean_test, noisy_train, noisy_test)
```

### 2. STFT Dataset

```python
from data_preparation import STFTDataset

# åˆ›å»º STFT æ•°æ®é›†
dataset = STFTDataset(
    clean_data=clean_train,
    noisy_data=noisy_train,
    n_fft=256,
    hop_length=64,
    mode='magnitude',  # æˆ– 'complex'
    normalize=True
)
```

### 3. æ¨¡å‹æ„å»º

```python
from unet_model import build_unet

# æ„å»ºæ¨¡å‹
model = build_unet(
    mode='magnitude',
    base_channels=64,
    depth=4,
    device='cuda'
)

# æŸ¥çœ‹æ¨¡å‹ä¿¡æ¯
model_info = model.get_model_size()
print(f"å‚æ•°é‡: {model_info['total_params']:,}")
print(f"æ¨¡å‹å¤§å°: {model_info['size_mb']:.2f} MB")
```

### 4. æ¨ç†

```python
from inference_unet import UNetInference

# åˆ›å»ºæ¨ç†å™¨
inferencer = UNetInference(
    model_path='checkpoints_unet/best.pth',
    device='cuda'
)

# å•ä¸ªä¿¡å·é™å™ª
denoised_signal = inferencer.denoise_signal(noisy_signal)

# æ‰¹é‡é™å™ª
denoised_signals = inferencer.denoise_batch(noisy_signals)
```

---

## ğŸ“ˆ è®­ç»ƒå»ºè®®

### è¶…å‚æ•°æ¨è

| æ•°æ®é‡ | Batch Size | Learning Rate | Epochs | æ—©åœè€å¿ƒ |
|--------|-----------|---------------|--------|---------|
| < 1000 æ ·æœ¬ | 8-16 | 5e-4 | 50-100 | 10 |
| 1000-5000 | 16-32 | 1e-3 | 100-200 | 15 |
| > 5000 | 32-64 | 1e-3 | 200-300 | 20 |

### STFT å‚æ•°æ¨è

| é‡‡æ ·ç‡ | n_fft | hop_length | æ—¶é—´åˆ†è¾¨ç‡ | é¢‘ç‡åˆ†è¾¨ç‡ |
|--------|-------|-----------|-----------|-----------|
| 250 Hz | 128 | 32 | 128 ms | ~2 Hz |
| 250 Hz | 256 | 64 | 256 ms | ~1 Hz |
| 250 Hz | 512 | 128 | 512 ms | ~0.5 Hz |

**é€‰æ‹©å»ºè®®ï¼š**
- EEG ä¿¡å·ï¼ˆä½é¢‘ä¸ºä¸»ï¼‰ï¼š`n_fft=256, hop_length=64`
- Audio ä¿¡å·ï¼ˆå®½é¢‘ï¼‰ï¼š`n_fft=512, hop_length=128`
- å¿«é€Ÿå˜åŒ–ä¿¡å·ï¼šå‡å° `hop_length` æé«˜æ—¶é—´åˆ†è¾¨ç‡

### å­¦ä¹ ç‡è°ƒåº¦

```bash
# ReduceLROnPlateauï¼ˆæ¨èï¼‰
python train_unet.py --scheduler plateau

# StepLR
python train_unet.py --scheduler step

# CosineAnnealing
python train_unet.py --scheduler cosine
```

---

## ğŸ¯ æ•°æ®å¢å¼ºç­–ç•¥

å½“æ•°æ®é‡ä¸è¶³æ—¶ï¼Œä½¿ç”¨ `data_augmentation.py` ä¸­çš„å¢å¼ºæ–¹æ³•ï¼š

```python
from data_augmentation import DataAugmentation

aug = DataAugmentation()

# 1. æ·»åŠ å™ªå£°
noisy_aug = aug.add_gaussian_noise(signal, noise_level=0.1)

# 2. æ—¶é—´å¹³ç§»
shifted = aug.time_shift(signal, max_shift=100)

# 3. å¹…åº¦ç¼©æ”¾
scaled = aug.amplitude_scale(signal, scale_range=(0.8, 1.2))

# 4. æ—¶é—´é®ç½©
masked = aug.time_mask(signal, num_masks=2, mask_len=50)

# 5. SpecAugmentï¼ˆåœ¨ STFT ä¸Šï¼‰
aug_stft = aug.spec_augment(stft, freq_mask_param=10, time_mask_param=10)

# 6. Mixup
mixed = aug.mixup(signal1, signal2, alpha=0.5)
```

**å¢å¼ºç­–ç•¥ç»„åˆå»ºè®®ï¼š**
- è®­ç»ƒåˆæœŸï¼šä»…ä½¿ç”¨è½»å¾®å™ªå£° + å¹…åº¦ç¼©æ”¾
- è®­ç»ƒä¸­æœŸï¼šæ·»åŠ æ—¶é—´å¹³ç§» + æ—¶é—´é®ç½©
- æ•°æ®ä¸¥é‡ä¸è¶³ï¼šä½¿ç”¨ Mixup + SpecAugment

---

## ğŸ“Š è¯„ä¼°æŒ‡æ ‡

æ¨ç†è„šæœ¬è‡ªåŠ¨è®¡ç®—ä»¥ä¸‹æŒ‡æ ‡ï¼š

1. **MSE (Mean Squared Error)**: å‡æ–¹è¯¯å·®
2. **MAE (Mean Absolute Error)**: å¹³å‡ç»å¯¹è¯¯å·®
3. **SNR (Signal-to-Noise Ratio)**: ä¿¡å™ªæ¯”æ”¹å–„
   - SNR Before: åŸå§‹å¸¦å™ªä¿¡å·çš„ SNR
   - SNR After: é™å™ªåä¿¡å·çš„ SNR
   - SNR Improvement: æ”¹å–„é‡ï¼ˆdBï¼‰

---

## ğŸ” TensorBoard ç›‘æ§

è®­ç»ƒè¿‡ç¨‹ä¸­å®æ—¶ç›‘æ§ï¼š

```bash
tensorboard --logdir logs_unet
```

å¯è§†åŒ–å†…å®¹ï¼š
- è®­ç»ƒ/éªŒè¯æŸå¤±æ›²çº¿
- L1/L2 æŸå¤±åˆ†é‡
- å­¦ä¹ ç‡å˜åŒ–
- æ¯ä¸ª epoch çš„æŒ‡æ ‡

---

## ğŸ“Œ å¸¸è§é—®é¢˜

### Q1: å†…å­˜ä¸è¶³æ€ä¹ˆåŠï¼Ÿ

**è§£å†³æ–¹æ¡ˆï¼š**
1. å‡å° `batch_size`ï¼ˆä¾‹å¦‚ä» 16 é™åˆ° 8ï¼‰
2. å‡å° `n_fft`ï¼ˆä¾‹å¦‚ä» 512 é™åˆ° 256ï¼‰
3. å‡å° `segment_length`ï¼ˆä¾‹å¦‚ä» 2048 é™åˆ° 1024ï¼‰
4. å‡å° U-Net æ·±åº¦æˆ–é€šé“æ•°

```bash
python train_unet.py --batch_size 8 --base_channels 32 --depth 3
```

### Q2: è®­ç»ƒé€Ÿåº¦æ…¢ï¼Ÿ

**ä¼˜åŒ–æ–¹æ³•ï¼š**
1. ä½¿ç”¨ GPUï¼šç¡®ä¿ `torch.cuda.is_available()` è¿”å› `True`
2. å¢åŠ  `num_workers`ï¼ˆä½† Windows å»ºè®®è®¾ä¸º 0ï¼‰
3. å‡å°æ•°æ®é›†ï¼ˆä½¿ç”¨ `--use_prepared_data` è·³è¿‡æ•°æ®å‡†å¤‡ï¼‰
4. ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼ˆéœ€æ‰‹åŠ¨æ·»åŠ  AMP æ”¯æŒï¼‰

### Q3: é™å™ªæ•ˆæœä¸å¥½ï¼Ÿ

**è°ƒä¼˜å»ºè®®ï¼š**
1. **æ£€æŸ¥ STFT å‚æ•°**ï¼šç¡®ä¿ `n_fft` å’Œ `hop_length` é€‚åˆä½ çš„ä¿¡å·ç‰¹æ€§
2. **å¢åŠ æ¨¡å‹å®¹é‡**ï¼š`--base_channels 128 --depth 5`
3. **è°ƒæ•´æŸå¤±æƒé‡**ï¼š`--l1_weight 1.0 --l2_weight 1.0`
4. **ä½¿ç”¨ complex æ¨¡å¼**ï¼š`--mode complex`ï¼ˆä¿ç•™ç›¸ä½ä¿¡æ¯ï¼‰
5. **å¢åŠ è®­ç»ƒæ•°æ®**ï¼šä½¿ç”¨æ•°æ®å¢å¼ºæˆ–æ”¶é›†æ›´å¤šæ•°æ®

### Q4: å¦‚ä½•åœ¨æ–°æ•°æ®ä¸Šæµ‹è¯•ï¼Ÿ

```python
from inference_unet import UNetInference
import numpy as np

# åŠ è½½æ¨¡å‹
inferencer = UNetInference('checkpoints_unet/best.pth')

# åŠ è½½ä½ çš„ä¿¡å·ï¼ˆä¸€ç»´ numpy æ•°ç»„ï¼‰
your_signal = np.load('your_signal.npy')

# é™å™ª
denoised = inferencer.denoise_signal(your_signal)

# ä¿å­˜
np.save('denoised_output.npy', denoised)
```

---

## ğŸ“œ è®¸å¯è¯

MIT License

---

## ğŸ™ è‡´è°¢

- U-Net æ¶æ„: [Ronneberger et al., 2015](https://arxiv.org/abs/1505.04597)
- SpecAugment: [Park et al., 2019](https://arxiv.org/abs/1904.08779)

---

**ä½œè€…**: GitHub Copilot  
**æ—¥æœŸ**: 2025-12-10  
**ç‰ˆæœ¬**: 1.0.0
