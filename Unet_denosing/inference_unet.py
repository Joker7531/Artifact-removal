"""
U-Net æ¨ç†ä¸å¯è§†åŒ–è„šæœ¬
æ”¯æŒå•æ–‡ä»¶æ¨ç†ã€æ‰¹é‡æ¨ç†å’Œç»“æœå¯è§†åŒ–
"""

import torch
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
import argparse
import json
from scipy import signal as scipy_signal

from unet_model import build_unet
from data_preparation import STFTDataset


class UNetInference:
    """
    U-Net æ¨ç†ç±»
    """
    def __init__(
        self,
        model_path: str,
        config_path: str = None,
        device: str = 'cuda'
    ):
        """
        Args:
            model_path: æ¨¡å‹æƒé‡è·¯å¾„
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            device: è®¾å¤‡
        """
        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')
        
        # åŠ è½½é…ç½®
        if config_path is None:
            config_path = Path(model_path).parent / 'config.json'
        
        if Path(config_path).exists():
            with open(config_path, 'r') as f:
                self.config = json.load(f)
        else:
            print(f"âš ï¸  æœªæ‰¾åˆ°é…ç½®æ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°")
            self.config = {
                'mode': 'magnitude',
                'base_channels': 64,
                'depth': 4,
                'n_fft': 256,
                'hop_length': 64
            }
        
        # æ„å»ºæ¨¡å‹
        self.model = build_unet(
            mode=self.config['mode'],
            base_channels=self.config['base_channels'],
            depth=self.config['depth'],
            device=self.device
        )
        
        # åŠ è½½æƒé‡
        checkpoint = torch.load(model_path, map_location=self.device)
        if 'model_state_dict' in checkpoint:
            self.model.load_state_dict(checkpoint['model_state_dict'])
        else:
            self.model.load_state_dict(checkpoint)
        
        self.model.eval()
        
        print(f"âœ… æ¨¡å‹å·²åŠ è½½: {model_path}")
        print(f"   æ¨¡å¼: {self.config['mode']}")
        print(f"   è®¾å¤‡: {self.device}")
    
    def _signal_to_stft(self, signal: np.ndarray) -> torch.Tensor:
        """
        ä¿¡å·è½¬ STFT
        
        Args:
            signal: (signal_length,)
        
        Returns:
            stft_tensor: (1, channels, freq, time)
        """
        n_fft = self.config['n_fft']
        hop_length = self.config['hop_length']
        
        # è®¡ç®— STFT
        stft = np.array([
            np.fft.rfft(signal[i:i+n_fft])
            for i in range(0, len(signal) - n_fft + 1, hop_length)
        ]).T  # (freq, time)
        
        if self.config['mode'] == 'magnitude':
            stft_mag = np.abs(stft)
            
            # å½’ä¸€åŒ–ï¼ˆä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
            stft_mag = np.log1p(stft_mag)
            stft_mag = (stft_mag - stft_mag.mean()) / (stft_mag.std() + 1e-8)
            
            stft_tensor = torch.FloatTensor(stft_mag).unsqueeze(0).unsqueeze(0)  # (1, 1, freq, time)
            phase = np.angle(stft)  # ä¿å­˜ç›¸ä½ç”¨äºé‡å»º
            
            return stft_tensor, phase
        
        elif self.config['mode'] == 'complex':
            real = np.real(stft)
            imag = np.imag(stft)
            
            # å½’ä¸€åŒ–
            for arr in [real, imag]:
                arr = (arr - arr.mean()) / (arr.std() + 1e-8)
            
            stft_tensor = torch.FloatTensor(np.stack([real, imag], axis=0)).unsqueeze(0)  # (1, 2, freq, time)
            
            return stft_tensor, None
    
    def _stft_to_signal(self, stft_tensor: torch.Tensor, phase: np.ndarray = None) -> np.ndarray:
        """
        STFT è½¬ä¿¡å·
        
        Args:
            stft_tensor: (1, channels, freq, time)
            phase: ç›¸ä½ï¼ˆä»… magnitude æ¨¡å¼éœ€è¦ï¼‰
        
        Returns:
            signal: (signal_length,)
        """
        stft_np = stft_tensor.squeeze(0).cpu().numpy()
        
        n_fft = self.config['n_fft']
        hop_length = self.config['hop_length']
        
        if self.config['mode'] == 'magnitude':
            # åå½’ä¸€åŒ–ï¼ˆéœ€è¦ä¿å­˜è®­ç»ƒæ—¶çš„ç»Ÿè®¡é‡ï¼Œè¿™é‡Œç®€åŒ–å¤„ç†ï¼‰
            # stft_mag = stft_np[0]  # (freq, time)
            # stft_mag = np.expm1(stft_mag)  # å log1p
            
            # ä½¿ç”¨ç›¸ä½é‡å»ºå¤æ•°è°±
            if phase is None:
                raise ValueError("Magnitude æ¨¡å¼éœ€è¦æä¾›ç›¸ä½")
            
            stft_mag = stft_np[0]
            stft_mag = np.expm1(stft_mag)
            stft_complex = stft_mag * np.exp(1j * phase)
        
        elif self.config['mode'] == 'complex':
            real = stft_np[0]
            imag = stft_np[1]
            stft_complex = real + 1j * imag
        
        # iSTFTï¼ˆé‡å ç›¸åŠ æ³•ï¼‰
        freq_bins, time_frames = stft_complex.shape
        signal_length = (time_frames - 1) * hop_length + n_fft
        
        signal = np.zeros(signal_length)
        window_sum = np.zeros(signal_length)
        
        for t in range(time_frames):
            frame = np.fft.irfft(stft_complex[:, t], n=n_fft)
            start = t * hop_length
            signal[start:start+n_fft] += frame
            window_sum[start:start+n_fft] += 1
        
        # å½’ä¸€åŒ–ï¼ˆé¿å…é™¤é›¶ï¼‰
        signal = np.divide(signal, window_sum, where=window_sum > 0)
        
        return signal
    
    @torch.no_grad()
    def denoise_signal(self, noisy_signal: np.ndarray) -> np.ndarray:
        """
        å¯¹å•ä¸ªä¿¡å·è¿›è¡Œé™å™ª
        
        Args:
            noisy_signal: (signal_length,)
        
        Returns:
            clean_signal: (signal_length,)
        """
        # è½¬ STFT
        stft_tensor, phase = self._signal_to_stft(noisy_signal)
        stft_tensor = stft_tensor.to(self.device)
        
        # æ¨ç†
        pred_stft = self.model(stft_tensor)
        
        # è½¬å›ä¿¡å·
        clean_signal = self._stft_to_signal(pred_stft, phase)
        
        # æˆªå–åˆ°åŸå§‹é•¿åº¦
        clean_signal = clean_signal[:len(noisy_signal)]
        
        return clean_signal
    
    def denoise_batch(self, noisy_signals: np.ndarray) -> np.ndarray:
        """
        æ‰¹é‡é™å™ª
        
        Args:
            noisy_signals: (N, signal_length)
        
        Returns:
            clean_signals: (N, signal_length)
        """
        clean_signals = []
        
        for i, noisy_sig in enumerate(noisy_signals):
            clean_sig = self.denoise_signal(noisy_sig)
            clean_signals.append(clean_sig)
            
            if (i + 1) % 10 == 0:
                print(f"   è¿›åº¦: {i+1}/{len(noisy_signals)}")
        
        return np.array(clean_signals)


def visualize_results(
    noisy_signal: np.ndarray,
    clean_signal: np.ndarray,
    denoised_signal: np.ndarray,
    save_path: str = None,
    n_fft: int = 256,
    hop_length: int = 64,
    fs: int = 250
):
    """
    å¯è§†åŒ–é™å™ªç»“æœ
    
    Args:
        noisy_signal: å¸¦å™ªä¿¡å·
        clean_signal: çœŸå®å¹²å‡€ä¿¡å·ï¼ˆå¯é€‰ï¼‰
        denoised_signal: é™å™ªåä¿¡å·
        save_path: ä¿å­˜è·¯å¾„
        n_fft: FFT ç‚¹æ•°
        hop_length: å¸§ç§»
        fs: é‡‡æ ·ç‡
    """
    fig, axes = plt.subplots(3, 3, figsize=(18, 12))
    
    # æ—¶é—´è½´
    time = np.arange(len(noisy_signal)) / fs
    
    # è®¡ç®— STFTï¼ˆç”¨äºå¯è§†åŒ–ï¼‰
    def compute_stft_vis(sig):
        f, t, Zxx = scipy_signal.stft(sig, fs=fs, nperseg=n_fft, noverlap=n_fft-hop_length)
        return f, t, np.abs(Zxx)
    
    # === ç¬¬ä¸€è¡Œï¼šæ—¶åŸŸæ³¢å½¢ ===
    axes[0, 0].plot(time, noisy_signal, label='Noisy', alpha=0.7)
    axes[0, 0].set_title('Noisy Signal (Time Domain)')
    axes[0, 0].set_xlabel('Time (s)')
    axes[0, 0].set_ylabel('Amplitude')
    axes[0, 0].legend()
    axes[0, 0].grid(True, alpha=0.3)
    
    if clean_signal is not None:
        axes[0, 1].plot(time, clean_signal, label='Clean (Ground Truth)', color='green', alpha=0.7)
        axes[0, 1].set_title('Clean Signal (Time Domain)')
        axes[0, 1].set_xlabel('Time (s)')
        axes[0, 1].set_ylabel('Amplitude')
        axes[0, 1].legend()
        axes[0, 1].grid(True, alpha=0.3)
    
    axes[0, 2].plot(time, denoised_signal, label='Denoised', color='red', alpha=0.7)
    axes[0, 2].set_title('Denoised Signal (Time Domain)')
    axes[0, 2].set_xlabel('Time (s)')
    axes[0, 2].set_ylabel('Amplitude')
    axes[0, 2].legend()
    axes[0, 2].grid(True, alpha=0.3)
    
    # === ç¬¬äºŒè¡Œï¼šé¢‘è°±å›¾ ===
    f_noisy, t_noisy, Zxx_noisy = compute_stft_vis(noisy_signal)
    axes[1, 0].pcolormesh(t_noisy, f_noisy, 20 * np.log10(Zxx_noisy + 1e-8), shading='gouraud', cmap='viridis')
    axes[1, 0].set_title('Noisy STFT')
    axes[1, 0].set_ylabel('Frequency (Hz)')
    axes[1, 0].set_xlabel('Time (s)')
    
    if clean_signal is not None:
        f_clean, t_clean, Zxx_clean = compute_stft_vis(clean_signal)
        axes[1, 1].pcolormesh(t_clean, f_clean, 20 * np.log10(Zxx_clean + 1e-8), shading='gouraud', cmap='viridis')
        axes[1, 1].set_title('Clean STFT')
        axes[1, 1].set_ylabel('Frequency (Hz)')
        axes[1, 1].set_xlabel('Time (s)')
    
    f_denoised, t_denoised, Zxx_denoised = compute_stft_vis(denoised_signal)
    axes[1, 2].pcolormesh(t_denoised, f_denoised, 20 * np.log10(Zxx_denoised + 1e-8), shading='gouraud', cmap='viridis')
    axes[1, 2].set_title('Denoised STFT')
    axes[1, 2].set_ylabel('Frequency (Hz)')
    axes[1, 2].set_xlabel('Time (s)')
    
    # === ç¬¬ä¸‰è¡Œï¼šå¯¹æ¯” ===
    if clean_signal is not None:
        # æ—¶åŸŸå¯¹æ¯”
        axes[2, 0].plot(time, clean_signal, label='Clean', color='green', alpha=0.7)
        axes[2, 0].plot(time, denoised_signal, label='Denoised', color='red', alpha=0.7, linestyle='--')
        axes[2, 0].set_title('Time Domain Comparison')
        axes[2, 0].set_xlabel('Time (s)')
        axes[2, 0].set_ylabel('Amplitude')
        axes[2, 0].legend()
        axes[2, 0].grid(True, alpha=0.3)
        
        # è¯¯å·®
        error = clean_signal - denoised_signal
        axes[2, 1].plot(time, error, color='purple', alpha=0.7)
        axes[2, 1].set_title(f'Reconstruction Error (MSE={np.mean(error**2):.4f})')
        axes[2, 1].set_xlabel('Time (s)')
        axes[2, 1].set_ylabel('Error')
        axes[2, 1].grid(True, alpha=0.3)
        
        # åŠŸç‡è°±å¯†åº¦
        f_clean_psd, psd_clean = scipy_signal.welch(clean_signal, fs=fs, nperseg=n_fft)
        f_denoised_psd, psd_denoised = scipy_signal.welch(denoised_signal, fs=fs, nperseg=n_fft)
        
        axes[2, 2].semilogy(f_clean_psd, psd_clean, label='Clean', color='green', alpha=0.7)
        axes[2, 2].semilogy(f_denoised_psd, psd_denoised, label='Denoised', color='red', alpha=0.7, linestyle='--')
        axes[2, 2].set_title('Power Spectral Density')
        axes[2, 2].set_xlabel('Frequency (Hz)')
        axes[2, 2].set_ylabel('PSD')
        axes[2, 2].legend()
        axes[2, 2].grid(True, alpha=0.3)
    else:
        # ä»…æ˜¾ç¤ºé™å™ªå‰åå¯¹æ¯”
        axes[2, 0].plot(time, noisy_signal, label='Noisy', alpha=0.7)
        axes[2, 0].plot(time, denoised_signal, label='Denoised', color='red', alpha=0.7, linestyle='--')
        axes[2, 0].set_title('Denoising Comparison')
        axes[2, 0].set_xlabel('Time (s)')
        axes[2, 0].set_ylabel('Amplitude')
        axes[2, 0].legend()
        axes[2, 0].grid(True, alpha=0.3)
    
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        print(f"ğŸ’¾ å¯è§†åŒ–å·²ä¿å­˜: {save_path}")
    
    plt.show()


def main(args):
    # åˆ›å»ºæ¨ç†å™¨
    inferencer = UNetInference(
        model_path=args.model_path,
        config_path=args.config_path,
        device=args.device
    )
    
    # åŠ è½½æµ‹è¯•æ•°æ®
    if args.test_clean_path and args.test_noisy_path:
        print(f"\nğŸ“‚ åŠ è½½æµ‹è¯•æ•°æ®...")
        clean_signals = np.load(args.test_clean_path)
        noisy_signals = np.load(args.test_noisy_path)
        
        print(f"   Clean: {clean_signals.shape}")
        print(f"   Noisy: {noisy_signals.shape}")
    else:
        # ä» dataset_mixed åŠ è½½
        clean_signals = np.load('dataset_mixed/test/clean/data.npy')
        noisy_signals = np.load('dataset_mixed/test/noisy/data.npy')
    
    # æ¨ç†
    print(f"\nğŸš€ å¼€å§‹æ¨ç†...")
    
    if args.num_samples > 0:
        num_samples = min(args.num_samples, len(noisy_signals))
        noisy_signals = noisy_signals[:num_samples]
        clean_signals = clean_signals[:num_samples]
    
    denoised_signals = inferencer.denoise_batch(noisy_signals)
    
    # è®¡ç®—æŒ‡æ ‡
    mse = np.mean((clean_signals - denoised_signals) ** 2)
    mae = np.mean(np.abs(clean_signals - denoised_signals))
    
    # SNR æ”¹å–„
    noise_before = clean_signals - noisy_signals
    noise_after = clean_signals - denoised_signals
    
    snr_before = 10 * np.log10(np.mean(clean_signals ** 2) / (np.mean(noise_before ** 2) + 1e-8))
    snr_after = 10 * np.log10(np.mean(clean_signals ** 2) / (np.mean(noise_after ** 2) + 1e-8))
    snr_improvement = snr_after - snr_before
    
    print(f"\nğŸ“Š è¯„ä¼°ç»“æœ:")
    print(f"   MSE: {mse:.6f}")
    print(f"   MAE: {mae:.6f}")
    print(f"   SNR (Before): {snr_before:.2f} dB")
    print(f"   SNR (After): {snr_after:.2f} dB")
    print(f"   SNR Improvement: {snr_improvement:.2f} dB")
    
    # ä¿å­˜ç»“æœ
    if args.save_results:
        output_dir = Path(args.output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        np.save(output_dir / 'denoised_signals.npy', denoised_signals)
        print(f"\nğŸ’¾ é™å™ªç»“æœå·²ä¿å­˜: {output_dir / 'denoised_signals.npy'}")
    
    # å¯è§†åŒ–
    if args.visualize:
        vis_dir = Path(args.output_dir) / 'visualizations'
        vis_dir.mkdir(parents=True, exist_ok=True)
        
        # å¯è§†åŒ–å‰å‡ ä¸ªæ ·æœ¬
        num_vis = min(args.num_visualize, len(noisy_signals))
        
        for i in range(num_vis):
            save_path = vis_dir / f'sample_{i:03d}.png'
            
            visualize_results(
                noisy_signal=noisy_signals[i],
                clean_signal=clean_signals[i],
                denoised_signal=denoised_signals[i],
                save_path=str(save_path),
                n_fft=inferencer.config['n_fft'],
                hop_length=inferencer.config['hop_length'],
                fs=args.sample_rate
            )


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='U-Net Denoising Inference')
    
    parser.add_argument('--model_path', type=str, default='checkpoints_unet/best.pth', 
                        help='æ¨¡å‹æƒé‡è·¯å¾„')
    parser.add_argument('--config_path', type=str, default=None, 
                        help='é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ä» checkpoint_dir è‡ªåŠ¨æŸ¥æ‰¾ï¼‰')
    parser.add_argument('--test_clean_path', type=str, default=None, 
                        help='æµ‹è¯•é›†å¹²å‡€ä¿¡å·è·¯å¾„')
    parser.add_argument('--test_noisy_path', type=str, default=None, 
                        help='æµ‹è¯•é›†å¸¦å™ªä¿¡å·è·¯å¾„')
    parser.add_argument('--num_samples', type=int, default=0, 
                        help='æ¨ç†æ ·æœ¬æ•°ï¼ˆ0 è¡¨ç¤ºå…¨éƒ¨ï¼‰')
    parser.add_argument('--device', type=str, default='cuda', 
                        choices=['cuda', 'cpu'], help='è®¾å¤‡')
    
    parser.add_argument('--save_results', action='store_true', 
                        help='ä¿å­˜é™å™ªç»“æœ')
    parser.add_argument('--output_dir', type=str, default='results_unet', 
                        help='è¾“å‡ºç›®å½•')
    
    parser.add_argument('--visualize', action='store_true', 
                        help='å¯è§†åŒ–ç»“æœ')
    parser.add_argument('--num_visualize', type=int, default=5, 
                        help='å¯è§†åŒ–æ ·æœ¬æ•°')
    parser.add_argument('--sample_rate', type=int, default=250, 
                        help='é‡‡æ ·ç‡ï¼ˆç”¨äºå¯è§†åŒ–ï¼‰')
    
    args = parser.parse_args()
    
    main(args)
