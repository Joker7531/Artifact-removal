"""
U-Net Denoising AutoEncoder for STFT-based Signal Denoising
æ”¯æŒ magnitude-only å’Œ complex (Re/Im) ä¸¤ç§æ¨¡å¼
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import List


class DoubleConv(nn.Module):
    """
    åŒå·ç§¯å±‚ï¼šConv -> BN -> ReLU -> Conv -> BN -> ReLU
    """
    def __init__(self, in_channels: int, out_channels: int):
        super().__init__()
        self.double_conv = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )
    
    def forward(self, x):
        return self.double_conv(x)


class Down(nn.Module):
    """
    ä¸‹é‡‡æ ·ï¼šMaxPool -> DoubleConv
    """
    def __init__(self, in_channels: int, out_channels: int):
        super().__init__()
        self.maxpool_conv = nn.Sequential(
            nn.MaxPool2d(2),
            DoubleConv(in_channels, out_channels)
        )
    
    def forward(self, x):
        return self.maxpool_conv(x)


class Up(nn.Module):
    """
    ä¸Šé‡‡æ ·ï¼šUpsample -> DoubleConvï¼ˆå«è·³è¿ï¼‰
    """
    def __init__(self, in_channels: int, out_channels: int, bilinear: bool = True):
        super().__init__()
        
        # in_channels æ˜¯è§£ç å™¨ä¸Šä¸€å±‚çš„è¾“å‡ºé€šé“æ•°
        # æ‹¼æ¥åé€šé“æ•° = in_channels + skip_channels (å…¶ä¸­ skip_channels = out_channels)
        if bilinear:
            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)
            # æ‹¼æ¥å: in_channels + out_channels -> out_channels
            self.conv = DoubleConv(in_channels + out_channels, out_channels)
        else:
            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)
            # æ‹¼æ¥å: in_channels // 2 + out_channels -> out_channels (æ³¨æ„è¿™é‡Œä¸Šé‡‡æ ·å·²ç»å‡åŠ)
            # ä½†ä¸ºäº†ç»Ÿä¸€ï¼Œæˆ‘ä»¬æœŸæœ› in_channels // 2 == out_channels
            self.conv = DoubleConv(in_channels, out_channels)
    
    def forward(self, x1, x2):
        """
        x1: æ¥è‡ªä¸Šå±‚çš„ä¸Šé‡‡æ ·ç‰¹å¾
        x2: æ¥è‡ªç¼–ç å™¨çš„è·³è¿ç‰¹å¾
        """
        x1 = self.up(x1)
        
        # å¤„ç†å°ºå¯¸ä¸åŒ¹é…ï¼ˆpaddingï¼‰
        diffY = x2.size()[2] - x1.size()[2]
        diffX = x2.size()[3] - x1.size()[3]
        
        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,
                        diffY // 2, diffY - diffY // 2])
        
        # æ‹¼æ¥è·³è¿
        x = torch.cat([x2, x1], dim=1)
        return self.conv(x)


class UNet(nn.Module):
    """
    U-Net Denoising AutoEncoder
    
    æ”¯æŒè‡ªåŠ¨è°ƒæ•´æ·±åº¦ä¸é€šé“æ•°
    è¾“å…¥/è¾“å‡º: (batch, channels, freq, time)
        - magnitude æ¨¡å¼: channels=1
        - complex æ¨¡å¼: channels=2 (Re, Im)
    """
    def __init__(
        self,
        in_channels: int = 1,
        out_channels: int = 1,
        base_channels: int = 64,
        depth: int = 4,
        bilinear: bool = True
    ):
        """
        Args:
            in_channels: è¾“å…¥é€šé“æ•° (1 for magnitude, 2 for complex)
            out_channels: è¾“å‡ºé€šé“æ•° (same as in_channels)
            base_channels: åŸºç¡€é€šé“æ•°ï¼ˆç¬¬ä¸€å±‚ï¼‰
            depth: ç½‘ç»œæ·±åº¦ï¼ˆä¸‹é‡‡æ ·æ¬¡æ•°ï¼‰
            bilinear: ä½¿ç”¨åŒçº¿æ€§æ’å€¼ä¸Šé‡‡æ ·ï¼ˆFalse åˆ™ç”¨è½¬ç½®å·ç§¯ï¼‰
        """
        super().__init__()
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.depth = depth
        self.bilinear = bilinear
        
        # åˆå§‹å·ç§¯
        self.inc = DoubleConv(in_channels, base_channels)
        
        # ç¼–ç å™¨ï¼ˆä¸‹é‡‡æ ·ï¼‰
        self.down_blocks = nn.ModuleList()
        ch = base_channels
        for i in range(depth):
            self.down_blocks.append(Down(ch, ch * 2))
            ch = ch * 2
        
        # è§£ç å™¨ï¼ˆä¸Šé‡‡æ ·ï¼‰
        self.up_blocks = nn.ModuleList()
        for i in range(depth):
            self.up_blocks.append(Up(ch, ch // 2, bilinear))
            ch = ch // 2
        
        # è¾“å‡ºå·ç§¯
        self.outc = nn.Conv2d(base_channels, out_channels, kernel_size=1)
    
    def forward(self, x):
        """
        Args:
            x: (batch, in_channels, freq, time)
        
        Returns:
            out: (batch, out_channels, freq, time)
        """
        # ç¼–ç å™¨
        x1 = self.inc(x)
        
        # ä¿å­˜è·³è¿ç‰¹å¾
        skip_connections = [x1]
        
        x_down = x1
        for down in self.down_blocks:
            x_down = down(x_down)
            skip_connections.append(x_down)
        
        # è§£ç å™¨ï¼ˆä½¿ç”¨è·³è¿ï¼‰
        x_up = skip_connections[-1]
        for i, up in enumerate(self.up_blocks):
            skip = skip_connections[-(i+2)]
            x_up = up(x_up, skip)
        
        # è¾“å‡º
        out = self.outc(x_up)
        
        return out
    
    def get_model_size(self):
        """
        è®¡ç®—æ¨¡å‹å‚æ•°é‡
        """
        total_params = sum(p.numel() for p in self.parameters())
        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)
        
        return {
            'total_params': total_params,
            'trainable_params': trainable_params,
            'size_mb': total_params * 4 / (1024 ** 2)  # å‡è®¾ float32
        }


class MultiScaleSTFTLoss(nn.Module):
    """
    å¤šåˆ†è¾¨ç‡ STFT æŸå¤±ï¼ˆç”¨äºæ—¶é¢‘åŸŸé‡å»ºï¼‰
    """
    def __init__(
        self,
        fft_sizes: List[int] = [512, 256, 128],
        hop_sizes: List[int] = [128, 64, 32],
        win_lengths: List[int] = [512, 256, 128],
        l1_weight: float = 1.0,
        l2_weight: float = 1.0
    ):
        super().__init__()
        self.fft_sizes = fft_sizes
        self.hop_sizes = hop_sizes
        self.win_lengths = win_lengths
        self.l1_weight = l1_weight
        self.l2_weight = l2_weight
    
    def stft(self, x, fft_size, hop_size, win_length):
        """
        è®¡ç®— STFTï¼ˆä»…ç”¨äºæŸå¤±è®¡ç®—ï¼Œä¸æ•°æ®é¢„å¤„ç†æ— å…³ï¼‰
        """
        # x: (batch, 1, freq, time) -> éœ€è¦å…ˆè½¬å›æ—¶åŸŸï¼ˆè¿™é‡Œç®€åŒ–ä¸ºç›´æ¥è®¡ç®—é¢‘è°±å·®ï¼‰
        return x
    
    def forward(self, pred, target):
        """
        è®¡ç®—å¤šå°ºåº¦ STFT æŸå¤±
        """
        total_loss = 0.0
        
        # L1 æŸå¤±ï¼ˆé¢‘è°±å¹…åº¦ï¼‰
        l1_loss = F.l1_loss(pred, target)
        
        # L2 æŸå¤±ï¼ˆé¢‘è°±èƒ½é‡ï¼‰
        l2_loss = F.mse_loss(pred, target)
        
        total_loss = self.l1_weight * l1_loss + self.l2_weight * l2_loss
        
        return total_loss


class CombinedLoss(nn.Module):
    """
    ç»„åˆæŸå¤±å‡½æ•°ï¼šL1 + L2 + Perceptualï¼ˆå¯é€‰ï¼‰
    """
    def __init__(
        self,
        l1_weight: float = 1.0,
        l2_weight: float = 1.0,
        use_multiscale: bool = False
    ):
        super().__init__()
        self.l1_weight = l1_weight
        self.l2_weight = l2_weight
        self.use_multiscale = use_multiscale
        
        if use_multiscale:
            self.multiscale_loss = MultiScaleSTFTLoss()
    
    def forward(self, pred, target):
        """
        Args:
            pred: é¢„æµ‹çš„ STFT (batch, channels, freq, time)
            target: ç›®æ ‡ STFT (batch, channels, freq, time)
        """
        # åŸºç¡€æŸå¤±
        l1_loss = F.l1_loss(pred, target)
        l2_loss = F.mse_loss(pred, target)
        
        total_loss = self.l1_weight * l1_loss + self.l2_weight * l2_loss
        
        # å¤šå°ºåº¦æŸå¤±ï¼ˆå¯é€‰ï¼‰
        if self.use_multiscale:
            ms_loss = self.multiscale_loss(pred, target)
            total_loss += 0.5 * ms_loss
        
        return total_loss, {
            'l1': l1_loss.item(),
            'l2': l2_loss.item(),
            'total': total_loss.item()
        }


def build_unet(
    mode: str = 'magnitude',
    base_channels: int = 64,
    depth: int = 4,
    device: str = 'cuda'
) -> UNet:
    """
    æ„å»º U-Net æ¨¡å‹çš„å¿«æ·å‡½æ•°
    
    Args:
        mode: 'magnitude' æˆ– 'complex'
        base_channels: åŸºç¡€é€šé“æ•°
        depth: ç½‘ç»œæ·±åº¦
        device: è®¾å¤‡
    
    Returns:
        model: UNet æ¨¡å‹
    """
    if mode == 'magnitude':
        in_channels = 1
        out_channels = 1
    elif mode == 'complex':
        in_channels = 2
        out_channels = 2
    else:
        raise ValueError(f"Unsupported mode: {mode}")
    
    model = UNet(
        in_channels=in_channels,
        out_channels=out_channels,
        base_channels=base_channels,
        depth=depth,
        bilinear=True
    )
    
    model = model.to(device)
    
    # æ‰“å°æ¨¡å‹ä¿¡æ¯
    model_info = model.get_model_size()
    print(f"\nğŸ—ï¸  U-Net æ¨¡å‹å·²æ„å»º (mode={mode})")
    print(f"   è¾“å…¥: (batch, {in_channels}, freq, time)")
    print(f"   è¾“å‡º: (batch, {out_channels}, freq, time)")
    print(f"   æ·±åº¦: {depth} å±‚")
    print(f"   åŸºç¡€é€šé“: {base_channels}")
    print(f"   å‚æ•°é‡: {model_info['total_params']:,}")
    print(f"   æ¨¡å‹å¤§å°: {model_info['size_mb']:.2f} MB")
    
    return model


if __name__ == "__main__":
    # æµ‹è¯•æ¨¡å‹
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    # Magnitude æ¨¡å¼
    model_mag = build_unet(mode='magnitude', base_channels=64, depth=4, device=device)
    
    # æµ‹è¯•å‰å‘ä¼ æ’­
    batch_size = 4
    freq_bins = 129  # n_fft // 2 + 1 (å‡è®¾ n_fft=256)
    time_frames = 64
    
    x_mag = torch.randn(batch_size, 1, freq_bins, time_frames).to(device)
    y_mag = model_mag(x_mag)
    
    print(f"\nâœ… Magnitude æ¨¡å¼æµ‹è¯•:")
    print(f"   è¾“å…¥: {x_mag.shape}")
    print(f"   è¾“å‡º: {y_mag.shape}")
    
    # Complex æ¨¡å¼
    model_cplx = build_unet(mode='complex', base_channels=64, depth=4, device=device)
    
    x_cplx = torch.randn(batch_size, 2, freq_bins, time_frames).to(device)
    y_cplx = model_cplx(x_cplx)
    
    print(f"\nâœ… Complex æ¨¡å¼æµ‹è¯•:")
    print(f"   è¾“å…¥: {x_cplx.shape}")
    print(f"   è¾“å‡º: {y_cplx.shape}")
    
    # æµ‹è¯•æŸå¤±å‡½æ•°
    criterion = CombinedLoss(l1_weight=1.0, l2_weight=0.5)
    target = torch.randn_like(y_mag)
    
    loss, loss_dict = criterion(y_mag, target)
    print(f"\nğŸ“Š æŸå¤±å‡½æ•°æµ‹è¯•:")
    print(f"   L1 Loss: {loss_dict['l1']:.4f}")
    print(f"   L2 Loss: {loss_dict['l2']:.4f}")
    print(f"   Total Loss: {loss_dict['total']:.4f}")
