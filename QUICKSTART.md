# å¿«é€Ÿå¼€å§‹æŒ‡å—

## ğŸ“ é¡¹ç›®ç»“æ„

```
GAN_Waveform/
â”œâ”€â”€ waveform_dataset.py         # æ•°æ®åŠ è½½
â”œâ”€â”€ waveform_models.py           # æ¨¡å‹å®šä¹‰
â”œâ”€â”€ train_waveform_gan.py        # è®­ç»ƒè„šæœ¬
â”œâ”€â”€ inference_waveform.py        # æ¨ç†è„šæœ¬
â”œâ”€â”€ test_all.py                  # æµ‹è¯•è„šæœ¬
â”œâ”€â”€ requirements.txt             # ä¾èµ–åŒ…
â””â”€â”€ README.md                    # è¯¦ç»†æ–‡æ¡£
```

## âš¡ å¿«é€Ÿå¼€å§‹ (3 æ­¥)

### 1. æµ‹è¯•ç³»ç»Ÿ

```bash
cd GAN_Waveform
python test_all.py
```

åº”è¯¥çœ‹åˆ°:
```
All Tests Passed! âœ“
```

### 2. å¼€å§‹è®­ç»ƒ

```bash
python train_waveform_gan.py
```

è®­ç»ƒå°†è‡ªåŠ¨:
- åŠ è½½ 6811 ä¸ªè®­ç»ƒæ ·æœ¬ (æ–‡ä»¶ 01-08)
- åŠ è½½ 1622 ä¸ªéªŒè¯æ ·æœ¬ (æ–‡ä»¶ 09-10)
- æ¯ 5 ä¸ª epoch ä¿å­˜ç»“æœ
- ä¿å­˜æœ€ä½³æ¨¡å‹åˆ° `checkpoints/best_model.pth`

### 3. æ¨ç†æµ‹è¯•

```bash
python inference_waveform.py
```

## ğŸ“Š æ¨¡å‹ä¿¡æ¯

- **ç”Ÿæˆå™¨**: 12,597,953 å‚æ•° (1D U-Net)
- **åˆ¤åˆ«å™¨**: 1,742,145 å‚æ•° (1D PatchGAN)
- **è¾“å…¥**: (Batch, 1, 300) - 3ç§’@100Hz
- **è¾“å‡º**: (Batch, 1, 300) - å»å™ªæ³¢å½¢

## ğŸ¯ ä¸»è¦ç‰¹ç‚¹

### vs STFT æ–¹æ³•
| ç‰¹æ€§ | æ—¶åŸŸ GAN âœ“ | STFT GAN |
|------|-----------|----------|
| ç›´æ¥é‡å»º | âœ“ | âœ— |
| æ— ç›¸ä½é—®é¢˜ | âœ“ | âœ— |
| è®­ç»ƒé€Ÿåº¦ | å¿« | æ…¢ |
| æ¨¡å‹å¤æ‚åº¦ | ä¸­ | é«˜ |

### æ¶æ„äº®ç‚¹
- **4å±‚ç¼–ç å™¨**: æ•æ‰å¤šå°ºåº¦ç‰¹å¾
- **è†¨èƒ€æ®‹å·®å—**: æ‰©å¤§æ„Ÿå—é‡ (dilation=1,2,4)
- **Skip Connections**: ä¿ç•™ç»†èŠ‚ä¿¡æ¯
- **è‡ªé€‚åº”æ’å€¼**: è‡ªåŠ¨å¤„ç†ç»´åº¦å¯¹é½

## âš™ï¸ é…ç½®å‚æ•°

```python
# train_waveform_gan.py ä¸­ä¿®æ”¹
config = {
    'batch_size': 32,        # æ˜¾å­˜å…è®¸å¯å¢å¤§
    'num_epochs': 100,       # è®­ç»ƒè½®æ•°
    'lambda_l1': 100,        # L1æƒé‡ (50-200)
    'window_sec': 3.0,       # çª—å£é•¿åº¦
    'overlap': 0.75,         # é‡å ç‡
}
```

## ğŸ“ˆ è®­ç»ƒç›‘æ§

å…³æ³¨æŒ‡æ ‡:
1. **Val L1 Loss** â¬‡ - ä¸»è¦ä¼˜åŒ–ç›®æ ‡
2. **G Loss vs D Loss** - åº”ä¿æŒå¹³è¡¡
3. **è®­ç»ƒæ›²çº¿** - æŸ¥çœ‹ `results/training_history.png`

## ğŸ”§ å¸¸è§é—®é¢˜

**Q: æ˜¾å­˜ä¸è¶³?**
```python
config['batch_size'] = 16  # å‡å° batch
config['base_filters'] = 32  # å‡å°æ¨¡å‹
```

**Q: è®­ç»ƒä¸ç¨³å®š?**
```python
config['lambda_l1'] = 150  # å¢å¤§L1æƒé‡
config['d_lr'] = 1e-4     # é™ä½Då­¦ä¹ ç‡
```

**Q: æ³¢å½¢è¿‡äºå¹³æ»‘?**
```python
config['lambda_l1'] = 50   # å‡å°L1æƒé‡
```

## ğŸ“ è¾“å‡ºæ–‡ä»¶

### è®­ç»ƒå
- `checkpoints/best_model.pth` - æœ€ä½³æ¨¡å‹
- `results/training_history.png` - æŸå¤±æ›²çº¿
- `results/waveform_samples_epoch_*.png` - æ³¢å½¢å¯¹æ¯”

### æ¨ç†å
- `results/inference/*_denoised.csv` - å»å™ªæ•°æ®
- `results/inference/*_denoised.png` - å¯¹æ¯”å›¾
- `results/inference/metrics.txt` - è¯„ä¼°æŒ‡æ ‡

## ğŸš€ æ€§èƒ½å‚è€ƒ

- **è®­ç»ƒé€Ÿåº¦**: ~20 it/s (GTX 1650 Ti)
- **epoch æ—¶é—´**: ~45ç§’ (6811 samples, batch=32)
- **æ¨ç†é€Ÿåº¦**: ~10ms/çª—å£ (GPU)

## ğŸ“ ä¸‹ä¸€æ­¥

1. è®­ç»ƒ 100 epochs
2. æŸ¥çœ‹ `results/` ä¸­çš„å¯è§†åŒ–
3. è°ƒæ•´è¶…å‚æ•°ä¼˜åŒ–æ€§èƒ½
4. åœ¨æ–°æ•°æ®ä¸Šæµ‹è¯•

---

**éœ€è¦å¸®åŠ©?** æŸ¥çœ‹ README.md è·å–å®Œæ•´æ–‡æ¡£
