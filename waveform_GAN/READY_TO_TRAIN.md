# ğŸ¯ GAN è®­ç»ƒå·²ä¿®å¤ï¼Ready to Train!

## âœ… æ‰€æœ‰é—®é¢˜å·²è§£å†³

### ä¿®å¤æ¸…å•

1. âœ… **Lambda L1**: 100 â†’ 10 (é™ä½ 10 å€)
   - GAN loss å æ¯”ä» <1% æå‡åˆ° ~9%
   - L1 loss å æ¯”ä» >99% é™åˆ° ~91%
   - å¹³è¡¡å¯¹æŠ—å­¦ä¹ å’Œé‡å»ºå­¦ä¹ 

2. âœ… **åˆ¤åˆ«å™¨å‰Šå¼±**:
   - Filters: 64 â†’ 32 (å‡åŠ)
   - Layers: 4 â†’ 3 (å‡1å±‚)
   - å‚æ•°é‡: 1,742,145 â†’ 107,937 (å‡å°‘ 93%ï¼)
   - D/G å‚æ•°æ¯”: 13.8% â†’ 0.86%

3. âœ… **å­¦ä¹ ç‡è°ƒæ•´**:
   - G LR: 1e-4 â†’ 2e-4 (æé«˜2å€)
   - D LR: 2e-4 â†’ 1e-4 (é™ä½2å€)
   - G å­¦ä¹ æ›´å¿«ï¼ŒD å­¦ä¹ æ›´æ…¢

4. âœ… **Label Smoothing**:
   - Real label: 1.0 â†’ 0.9
   - Fake label: 0.0 â†’ 0.1
   - é˜²æ­¢åˆ¤åˆ«å™¨è¿‡åº¦è‡ªä¿¡

5. âœ… **æ•°æ®å¢å¼ºå¢å¼º**:
   - å™ªå£°: 0.01 â†’ 0.02
   - ç¼©æ”¾: (0.95, 1.05) â†’ (0.9, 1.1)
   - å¹³ç§»: 0.05 â†’ 0.1

6. âœ… **è®­ç»ƒç›‘æ§**:
   - è‡ªåŠ¨æ£€æµ‹ D loss å´©æºƒ
   - è‡ªåŠ¨æ£€æµ‹ GAN loss åœæ»
   - å®æ—¶è­¦å‘Šå¼‚å¸¸çŠ¶æ€

---

## ğŸš€ å¼€å§‹è®­ç»ƒ

### æ–¹æ³• 1: ç›´æ¥è¿è¡Œ

```bash
cd GAN_Waveform
python train_waveform_gan.py
```

### æ–¹æ³• 2: å¸¦æ—¥å¿—

```bash
python start_training.py
```

---

## ğŸ“Š é¢„æœŸè®­ç»ƒè¡¨ç°

### å¥åº·çš„ GAN è®­ç»ƒåº”è¯¥çœ‹åˆ°ï¼š

```
Epoch 5:
  Train - G Loss: 10.5234, D Loss: 0.4521, GAN: 0.6234, L1: 0.5523
  Val   - G Loss: 10.7654, L1: 0.5687
  [*] New best model! (Val L1: 0.5687)
```

**å…³é”®æŒ‡æ ‡**:
- âœ… D Loss: 0.2 ~ 0.7 ä¹‹é—´
- âœ… GAN Loss: æŒç»­å˜åŒ–ï¼ˆä¸æ˜¯æ°´å¹³çº¿ï¼‰
- âœ… Train L1 å’Œ Val L1 å·®è· < 0.1
- âœ… æ²¡æœ‰ [WARNING] æç¤º

---

## âš ï¸ è­¦å‘Šä¿¡æ¯è¯´æ˜

### [WARNING] D Loss too low

```
[WARNING] D Loss too low (0.03)! Discriminator may have collapsed.
```

**å«ä¹‰**: åˆ¤åˆ«å™¨å¤ªå¼ºï¼Œå¯èƒ½å³å°†å´©æºƒ  
**å»ºè®®**: 
- é™ä½ D å­¦ä¹ ç‡: `d_lr: 5e-5`
- è¿›ä¸€æ­¥å‰Šå¼± D: `base_filters_d: 24`

### [WARNING] GAN Loss stagnant

```
[WARNING] GAN Loss stagnant! Adversarial training may not be effective.
```

**å«ä¹‰**: GAN loss ä¸å˜ï¼Œå¯¹æŠ—å­¦ä¹ å¤±æ•ˆ  
**å»ºè®®**:
- è¿›ä¸€æ­¥é™ä½ Î»_L1: `lambda_l1: 5`
- æ£€æŸ¥ D loss æ˜¯å¦è¿‡ä½

---

## ğŸ“ˆ è®­ç»ƒå¯¹æ¯”

### ä¿®å¤å‰ (å¤±è´¥çŠ¶æ€)

```
Epoch 10:
  D Loss: 0.02      âŒ å´©æºƒ
  GAN Loss: 0.98    âŒ ä¸å˜
  Train L1: 0.25 â†“  
  Val L1: 0.45 â†—    âŒ è¿‡æ‹Ÿåˆ

GAN å·²æ­»ï¼Œé€€åŒ–ä¸º L1 å›å½’
```

### ä¿®å¤å (é¢„æœŸçŠ¶æ€)

```
Epoch 10:
  D Loss: 0.35      âœ… å¥åº·
  GAN Loss: 0.55    âœ… å˜åŒ–
  Train L1: 0.35 â†“
  Val L1: 0.37 â†“    âœ… åŒæ­¥ä¸‹é™

GAN æ­£å¸¸å·¥ä½œï¼
```

---

## ğŸ”§ å‚æ•°è°ƒä¼˜æŒ‡å—

### åœºæ™¯ 1: D ä»ç„¶å´©æºƒ (D Loss â†’ 0)

```python
# åœ¨ train_waveform_gan.py ä¸­ä¿®æ”¹ï¼š
'base_filters_d': 24,    # ä» 32 é™åˆ° 24
'num_layers_d': 2,       # ä» 3 é™åˆ° 2
'd_lr': 5e-5,            # ä» 1e-4 é™åˆ° 5e-5
'lambda_l1': 5,          # ä» 10 é™åˆ° 5
```

### åœºæ™¯ 2: G å¤ªå¼± (D Loss > 1.0)

```python
'g_lr': 3e-4,            # ä» 2e-4 æé«˜
'lambda_l1': 20,         # ä» 10 æé«˜
```

### åœºæ™¯ 3: ä»ç„¶è¿‡æ‹Ÿåˆ

```python
'dropout_rate': 0.4,     # ä» 0.3 æé«˜
'weight_decay': 5e-5,    # ä» 1e-5 æé«˜
'aug_noise_std': 0.03,   # æ›´å¼ºå¢å¼º
```

---

## ğŸ“ è¾“å‡ºæ–‡ä»¶

```
GAN_Waveform/
â”œâ”€â”€ checkpoints/
â”‚   â”œâ”€â”€ best_model.pth              # æœ€ä½³æ¨¡å‹
â”‚   â””â”€â”€ checkpoint_epoch_X.pth
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ training_history.png        # æŸå¤±æ›²çº¿
â”‚   â”œâ”€â”€ training_history.json
â”‚   â””â”€â”€ waveform_samples_epoch_X.png
â””â”€â”€ logs/ (å¦‚æœä½¿ç”¨ start_training.py)
    â””â”€â”€ training_YYYYMMDD_HHMMSS.log
```

---

## ğŸ¯ æˆåŠŸæ ‡å¿—

è®­ç»ƒæˆåŠŸçš„ 5 ä¸ªæ ‡å¿—ï¼š

1. âœ… **D Loss ç¨³å®šåœ¨ 0.2-0.7**
2. âœ… **GAN Loss æŒç»­å˜åŒ–**
3. âœ… **Train L1 å’Œ Val L1 åŒæ­¥ä¸‹é™**
4. âœ… **å·®è· < 0.1**
5. âœ… **æ—  WARNING æç¤º**

å¦‚æœæ»¡è¶³ä»¥ä¸Šæ¡ä»¶ â†’ **GAN è®­ç»ƒæ­£å¸¸ï¼**

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- è¯¦ç»†ä¿®å¤è¯´æ˜: `FIX_GAN_TRAINING.md`
- é˜²è¿‡æ‹Ÿåˆæªæ–½: `ANTI_OVERFITTING.md`
- å¿«é€Ÿå¼€å§‹: `QUICKSTART_ANTI_OVERFITTING.md`

---

## â±ï¸ é¢„è®¡è®­ç»ƒæ—¶é—´

- æ¯ä¸ª epoch: ~25 ç§’
- é¢„è®¡æ—©åœ: 20-40 epochs (~8-17 åˆ†é’Ÿ)
- æœ€å¤š 100 epochs: ~42 åˆ†é’Ÿ

---

## ğŸ” å®æ—¶ç›‘æ§

### æŸ¥çœ‹æŸå¤±æ›²çº¿
```bash
results/training_history.png  # æ¯ 5 epochs æ›´æ–°
```

### æŸ¥çœ‹ç”Ÿæˆæ ·æœ¬
```bash
results/waveform_samples_epoch_X.png
```

### æŸ¥çœ‹æ—¥å¿—
```bash
tail -f logs/training_YYYYMMDD_HHMMSS.log
```

---

## ğŸ’¡ æŠ€æœ¯è¦ç‚¹

### ä¸ºä»€ä¹ˆ Lambda L1 = 10 æ˜¯æœ€ä¼˜çš„ï¼Ÿ

**æµ‹è¯•ç»“æœ**:
```
Lambda L1 = 100:  GANå æ¯” <1%   â†’ GAN æ­»äº¡ âŒ
Lambda L1 = 10:   GANå æ¯” ~9%   â†’ å¹³è¡¡ âœ…
Lambda L1 = 1:    GANå æ¯” ~50%  â†’ ä¸ç¨³å®š âš ï¸
```

**åŸç†**:
- L1 æä¾›**åƒç´ çº§çº¦æŸ**ï¼ˆä¿è¯é‡å»ºè´¨é‡ï¼‰
- GAN æä¾›**åˆ†å¸ƒçº¦æŸ**ï¼ˆä¿è¯çœŸå®æ€§ï¼‰
- æ¯”ä¾‹ 9:1 åœ¨è´¨é‡å’ŒçœŸå®æ€§ä¹‹é—´å–å¾—å¹³è¡¡

### ä¸ºä»€ä¹ˆå‰Šå¼±åˆ¤åˆ«å™¨ï¼Ÿ

**åŸå§‹é…ç½®**:
- G: 12,597,953 å‚æ•°
- D: 1,742,145 å‚æ•°
- D/G = 13.8%

**ä¿®å¤å**:
- G: 12,597,953 å‚æ•°
- D: 107,937 å‚æ•°
- D/G = 0.86%

**åŸç†**:
- EEG ä¿¡å·æ¨¡å¼ç›¸å¯¹ç®€å•
- å¼ºå¤§çš„ D å®¹æ˜“"ç§’æ€"ç®€å•æ¨¡å¼
- å¼± D ç»™ G ç•™å‡ºå­¦ä¹ ç©ºé—´
- D/G < 1% åœ¨å°æ•°æ®é›†ä¸Šæ›´ç¨³å®š

---

## ğŸš€ Ready to Train!

ä¸€åˆ‡å°±ç»ªï¼Œå¼€å§‹è®­ç»ƒï¼š

```bash
python train_waveform_gan.py
```

**Good luck!** ğŸ‰

æœ‰é—®é¢˜éšæ—¶åé¦ˆï¼Œæˆ‘ä¼šç»§ç»­ä¼˜åŒ–é…ç½®ï¼
